# 2025 - Python challenge

This Python challenge was design for the students of I edition of the Master in Big Data, artificial integiligence and data engineering at the University of MÃ¡laga.

This challenge is design in a modular format so if you get stuck on one of the steps you could continue working on the rest, while covering **most** of the topics studied during the course.


## The challenge

The goal of this challenge is to create an end-to-end application to classify animals in four classes (Kangaroo, Elephant, Chicken and Dog) based on a set of characteristics.

The challenge is split in 5 steps, each one building on top of the previous one. You can choose to complete all of them or just some of them.

Each point will have a main goal and a set of self-evaluation points that you can use to check if you have fulfilled all the requirements to implement a quality solution, some of them are considered extra and are not required for the solution to work.

### 0 - General requirements
To practice in a more real-world scenario, you should use git to version your code and GitHub to submit your solution. Follow the best practices of git, like writing meaningful commit messages, using branches and pull requests (even only by yourself).

Additionally, try to follow the best practices of Python, like using type hints, docstrings, and PEP8 style guide (bonus points for configuring a linter like ruff or black in your project).

Split your code in modules and functions to make it more readable and reusable.

### 1 - Prepare the development environment
I have prepared a service that will provide you with the data that will be required for the rest of the steps

Check [`data-service`/](data-service/) for intructions on the deployment. You should not need to read or modify the Python code, treat this as an external service that you deploy locally.

All you need is in the README.md or the web application itself.

**Main goal**: You have a local instance of the data service you can connect to obtain data.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have built the container with the instructions provided
- [ ] You have deployed the container with the instructions provided
- [ ] You can access the app and its documentation in your local machine
- [ ] You can request data and receive it through one of the provided test commands

</details>


### 2 - Data pre-processing and Machine learning
With the data generated by the data service, we want to classify at least 1000 datapoints in the 4 classes provided (Kangaroo, Elephant, Chicken and Dog).

Visualize the data to better understand it, clean it from outliers and train a machine learning model to classify the data.

> [!NOTE]  
> Data received from the data service is not labeled. This is left as an exercise for you to solve.
>
> There are more than one way to solve this problem, you can choose the one that you feel more comfortable with.


**Main goal**: Have a Python script to remove outliers and classify the data and a Jupyter notebook with the visualizations used.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have read all information you could gather on the data from data service.
- [ ] You have prepared a dataset with at least 1000 datapoints locally from the data service
- [ ] You have visualized the data to better understand its structure
- [ ] You have cleaned the data from outliers
- [ ] You have trained a machine learning model in the data to solve the requested task
- [ ] You have stored the model in a way that can be loaded later
- [ ] You have validated the results from the model according to the knowledge you have on the data
- [ ] (EXTRA) If your apprach allows it, provide a confidence interval for the predictions.
- [ ] (EXTRA) When training the model, you store it in a object storage (like https://min.io) instead of the local filesystem

</details>

### 3 - Backend development
Create an API that uses the model trained in the previous excercise to classify data provided by an user.

Main goal: You have a REST API that can be queried to classify new data.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have a REST API which you can access the documentation
- [ ] You have an endpoint to predict a data point
- [ ] (EXTRA) You have an endpoint to re-train the model with new data
- [ ] (EXTRA) Your API is properly typed with Pydantic models
- [ ] (EXTRA) Your API is built as a Python package
- [ ] (EXTRA) Your API have a cli command that allows configuring basic parameters
- [ ] (EXTRA) Your API loads the model from an object storage instead of the local filesystem
- [ ] (EXTRA) Implement at least 5 unit tests for some of your functions
- [ ] (EXTRA) When running the tests, you measure the coverage of your tests
- [ ] (EXTRA) Your package has a README that explains how to deploy the app and basic information about how to use it (running, tests, etc)
</details>

### 4 - Front-end PoC/Visualization
Build a dashboard (for example with [streamlit](https://streamlit.io/)) that can be used as a client around the API built in the previous step.

**Main goal**: A web interface accesible through the browser is available for the users to provide a new sample and get a classification on it.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] You have a web app that can be access it through a browser
- [ ] The user can input its data through the web app
- [ ] When a user sends its data, the backend is contacted to classify it.
- [ ] (EXTRA) When the user sends its data, the data and the classification is stored in a SQL database so it can be used for re-training the model in the future
- [ ] (EXTRA) If data is being stored in a database, the web app can show the user a table with the data it has sent and the classification it received
- [ ] (EXTRA) Your web app is built as a Python package
- [ ] (EXTRA) Your package has a README that explains how to deploy the app and basic information about it

</details>


### 5 - Containerization
To facilitate the deployment of all the components created, create a container for each of them.

Additionally, prepare a docker compose file that will help end users deploy **all** the components together on a single command.

**Main goal**: A single command can be used to run the whole application, including backend, frontend and the data service provided.

<details>
<summary>Self-evaluation of your progress</summary>

- [ ] The backend can be deployed with docker
- [ ] The web app can be deployed with docker
- [ ] (EXTRA) There is a docker compose file in the root of the repository that deploys the data-service, the backend and the web app directly.
- [ ] (EXTRA) If applicable, the database used by the backend is also deployed with docker and configured in the docker compose file
- [ ] (EXTRA) Each part's README.md includes documentation on deploying with Docker

</details>

# How to submit your solution for evaluation?

First, create a repository in your GitHub account with the solution to the challenge, please make sure to include a README.md file with instructions on how to run your solution.

Once you are done with the challenge, please open a pull request in this repository, modifying this README.md by adding a link to your repository in the table below.

Then I will provide feedback on your solution and we can discuss it further inside the PR. Additionally, the rest of the students can see your solution and the feedback provided, so we can learn from everyone.

# Solutions to this challenge

| Link to repostory |
|-------------------|
| Add yours below   |